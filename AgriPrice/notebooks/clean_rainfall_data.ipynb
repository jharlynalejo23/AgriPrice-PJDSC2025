{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de106053-9678-4038-ad35-3e9a65ac3310",
   "metadata": {},
   "source": [
    "# Rainfall Data Preparation: Cleaning and Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecab34-faef-4501-937c-cb1d5fca5891",
   "metadata": {},
   "source": [
    "This notebook processes the raw rainfall data to create a clean, tidy, and geo-located dataset. This data will be later merged with the cleaned food price data to form the final panel dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c4eef1-c1f3-453f-af03-15fbdb61d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "\n",
    "RAW_EXCEL_PATH = \"raw_dataset/Table 1.2 Amount of Rainfall by Monitoring Station, 2015-2024.xlsx\"\n",
    "CLEANED_DATA_DIR = \"data_cleaned\"\n",
    "OUTPUT_FILE_TIDY = os.path.join(CLEANED_DATA_DIR, \"rainfall_2021_2024_tidy.csv\")\n",
    "OUTPUT_FILE_MAPREADY = os.path.join(CLEANED_DATA_DIR, \"rainfall_2021_2024_mapready.csv\")\n",
    "\n",
    "TARGET_YEARS = ['2021', '2022', '2023', '2024']\n",
    "\n",
    "os.makedirs(CLEANED_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5e8dc4-351e-47c9-8839-fe2e32e190c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/r__l3n2d23s7_2w_328wzkpc0000gn/T/ipykernel_14925/1362530979.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).strip() if pd.notnull(x) else x)\n",
      "/var/folders/kk/r__l3n2d23s7_2w_328wzkpc0000gn/T/ipykernel_14925/1362530979.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).strip() if pd.notnull(x) else x)\n",
      "/var/folders/kk/r__l3n2d23s7_2w_328wzkpc0000gn/T/ipykernel_14925/1362530979.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).strip() if pd.notnull(x) else x)\n",
      "/var/folders/kk/r__l3n2d23s7_2w_328wzkpc0000gn/T/ipykernel_14925/1362530979.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).strip() if pd.notnull(x) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Processed sheet: 2021. Rows: 696\n",
      "  ✅ Processed sheet: 2022. Rows: 695\n",
      "  ✅ Processed sheet: 2023. Rows: 696\n",
      "  ✅ Processed sheet: 2024. Rows: 654\n",
      "All rainfall data combined and saved to: data_cleaned/rainfall_2021_2024_tidy.csv\n",
      "Total Tidy Rainfall Rows: 2741\n"
     ]
    }
   ],
   "source": [
    "def clean_sheet(sheet_name, file_path):\n",
    "    \"\"\"Loads a single Excel sheet, cleans up junk rows, and melts the monthly data.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sheet '{sheet_name}': {e}\")\n",
    "        return None\n",
    "\n",
    "    # Strip spaces from all string cells\n",
    "    df = df.applymap(lambda x: str(x).strip() if pd.notnull(x) else x)\n",
    "\n",
    "    # Remove data after the \"Notes:\" section\n",
    "    footnote_start = df.apply(lambda row: row.astype(str).str.contains(r'(?i)notes')).any(axis=1)\n",
    "    if footnote_start.any():\n",
    "        first_note_index = footnote_start[footnote_start].index[0]\n",
    "        df = df.loc[:first_note_index - 1]\n",
    "\n",
    "    # Drop fully empty rows and columns\n",
    "    df = df.dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "\n",
    "    # Rename and drop non-data columns\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.rename(columns={'Unnamed: 0': 'Monitoring Station'})\n",
    "    if 'Annual' in df.columns:\n",
    "        df = df.drop(columns=['Annual'])\n",
    "\n",
    "    df_long = df.melt(\n",
    "        id_vars=['Monitoring Station'],\n",
    "        var_name='Month',\n",
    "        value_name='Rainfall'\n",
    "    )\n",
    "\n",
    "    # Add year column\n",
    "    df_long['Year'] = sheet_name\n",
    "    \n",
    "    # Drop rows where the station name or rainfall is missing/junk\n",
    "    df_long = df_long.dropna(subset=['Monitoring Station', 'Rainfall'])\n",
    "    df_long = df_long[df_long['Monitoring Station'] != '']\n",
    "    df_long['Rainfall'] = pd.to_numeric(df_long['Rainfall'], errors='coerce')\n",
    "    \n",
    "    return df_long\n",
    "\n",
    "dfs = []\n",
    "for year in TARGET_YEARS:\n",
    "    df_result = clean_sheet(year, RAW_EXCEL_PATH)\n",
    "    if df_result is not None:\n",
    "        dfs.append(df_result)\n",
    "        print(f\"  ✅ Processed sheet: {year}. Rows: {len(df_result)}\")\n",
    "\n",
    "if dfs:\n",
    "    df_all_tidy = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    df_all_tidy['Year'] = df_all_tidy['Year'].astype(int)\n",
    "    \n",
    "    df_all_tidy.to_csv(OUTPUT_FILE_TIDY, index=False)\n",
    "    print(f\"All rainfall data combined and saved to: {OUTPUT_FILE_TIDY}\")\n",
    "    print(f\"Total Tidy Rainfall Rows: {len(df_all_tidy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1040d91e-f170-413b-b7f2-aa06be2fb432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/61] Found: Alabat, Quezon\n",
      "[2/61] Found: Ambulong, Batangas\n",
      "[3/61] Found: Aparri, Cagayan\n",
      "[4/61] Found: Baguio City, Benguet\n",
      "[5/61] Found: Baler, Aurora (Radar)\n",
      "[6/61] Found: Basco, Batanes (Radar)\n",
      "[7/61] Found: Borongan, Eastern Samar\n",
      "[8/61] Found: Butuan City, Agusan Del Norte\n",
      "[9/61] Manual hit: Cabanatuan, Nueva Ecija (Station was transferred to CLSU, Nueva Ecija)\n",
      "[10/61] Found: Calapan, Oriental Mindoro\n",
      "[11/61] Found: Calayan, Cagayan\n",
      "[12/61] Found: Casiguran, Aurora\n",
      "[13/61] Found: Catarman, Northern Samar\n",
      "[14/61] Found: Catbalogan, Western Samar\n",
      "[15/61] Found: Clark International Airport, Pampanga\n",
      "[16/61] Manual hit: CLSU, Nueva Ecija\n",
      "[17/61] Found: Coron, Palawan\n",
      "[18/61] Found: Cotabato City, Maguindanao\n",
      "[19/61] Manual hit: Cubi Point, Subic Bay Olongapo City, Zambales\n",
      "[20/61] Found: Cuyo, Palawan\n",
      "[21/61] Found: Daet, Camarines Norte\n",
      "[22/61] Found: Dagupan City, Pangasinan\n",
      "[23/61] Found: Dauis, Bohol\n",
      "[24/61] Found: Davao City, Davao Del Sur\n",
      "[25/61] Found: Dipolog, Zamboanga Del Norte\n",
      "[26/61] Found: Dumaguete City, Negros Oriental\n",
      "[27/61] Manual hit: Molugan-El Salvador, Misamis Oriental (former Lumbia Station)\n",
      "[28/61] Found: General Santos, South Cotabato\n",
      "[29/61] Found: Guiuan, Eastern Samar\n",
      "[30/61] Found: Hinatuan, Surigao Del Sur\n",
      "[31/61] Found: Iba, Zambales\n",
      "[32/61] Found: Infanta, Quezon\n",
      "[33/61] Found: Itbayat, Batanes\n",
      "[34/61] Found: Juban, Sorsogon\n",
      "[35/61] Found: Laoag City, Ilocos Norte\n",
      "[36/61] Found: Legazpi City, Albay\n",
      "[37/61] Found: Lumbia, Misamis Oriental\n",
      "[38/61] Found: Maasin, Southern Leyte\n",
      "[39/61] Manual hit: Mactan International Airport, Cebu\n",
      "[40/61] Found: Malaybalay, Bukidnon\n",
      "[41/61] Found: Masbate, Masbate\n",
      "[42/61] Manual hit: NAIA (MIA), Pasay City\n",
      "[43/61] Manual hit: Port Area (MCO), Manila\n",
      "[44/61] Found: Puerto Princesa City, Palawan\n",
      "[45/61] Found: Romblon, Romblon\n",
      "[46/61] Found: Roxas City, Capiz\n",
      "[47/61] Found: San Jose, Occidental Mindoro\n",
      "[48/61] Found: Sangley Point, Cavite\n",
      "[49/61] Manual hit: Science Garden, Quezon City\n",
      "[50/61] Manual hit: Sinait, Ilocos Sur (former Vigan Station)\n",
      "[51/61] Found: Surigao, Surigao Del Norte\n",
      "[52/61] Manual hit: Tagbilaran City, Bohol (Station was transferred to Dauis, Bohol)\n",
      "[53/61] Found: Tacloban City, Leyte\n",
      "[54/61] Found: Tanay, Rizal\n",
      "[55/61] Found: Tayabas, Quezon\n",
      "[56/61] Found: Tuguegarao, Cagayan\n",
      "[57/61] Manual hit: Virac Synop, Catanduanes\n",
      "[58/61] Found: Zamboanga, Zamboanga Del Sur\n",
      "[59/61] Found: Laguindingan Airport, Misamis Oriental\n",
      "[60/61] Found: Mulanay, Quezon\n",
      "[61/61] Found: Panglao, Bohol\n",
      "\n",
      " FINAL Map-ready dataset saved to: data_cleaned/rainfall_2021_2024_mapready.csv\n",
      "\n",
      " All stations successfully geocoded!\n"
     ]
    }
   ],
   "source": [
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"agriprice_rainfall_geocoder\", timeout=10)\n",
    "\n",
    "# --- Manual Coordinate Fixes ---\n",
    "MANUAL_COORDS = {\n",
    "    \"CLSU, Nueva Ecija\": (15.7328, 120.9310),\n",
    "    \"Molugan-El Salvador, Misamis Oriental (former Lumbia Station)\": (8.5745, 124.5382),\n",
    "    \"Port Area (MCO), Manila\": (14.5833, 120.9667),\n",
    "    \"Science Garden, Quezon City\": (14.6488, 121.0330),\n",
    "    \"NAIA (MIA), Pasay City\": (14.5086, 121.0198),\n",
    "    \"Tagbilaran City, Bohol (Station was transferred to Dauis, Bohol)\": (9.6174, 123.8611),\n",
    "    \"Cabanatuan, Nueva Ecija (Station was transferred to CLSU, Nueva Ecija)\": (15.7328, 120.9310),\n",
    "    \"Sinait, Ilocos Sur (former Vigan Station)\": (17.8674, 120.4570),\n",
    "    \"Cubi Point, Subic Bay Olongapo City, Zambales\": (14.7708, 120.2608),\n",
    "    \"Mactan International Airport, Cebu\": (10.3073, 123.9744),\n",
    "    \"Virac Synop, Catanduanes\": (13.5858, 124.2378),\n",
    "}\n",
    "\n",
    "def clean_station_name(name: str) -> str:\n",
    "    name = name.replace(\" Synop\", \"\").strip() \n",
    "    if \"(\" in name:\n",
    "        name = name.split(\"(\")[0].strip()\n",
    "    return name\n",
    "\n",
    "\n",
    "stations = df_all_tidy['Monitoring Station'].unique()\n",
    "coords = []\n",
    "\n",
    "for i, station in enumerate(stations):\n",
    "    if station in MANUAL_COORDS:\n",
    "        lat, lon = MANUAL_COORDS[station]\n",
    "        print(f\"[{i+1}/{len(stations)}] Manual hit: {station}\")\n",
    "    else:\n",
    "        clean_name = clean_station_name(station)\n",
    "        location = None\n",
    "        \n",
    "        queries = [\n",
    "            f\"{clean_name} PAGASA Weather Station, Philippines\",\n",
    "            f\"{clean_name}, Philippines\",\n",
    "        ]\n",
    "        \n",
    "        for q in queries:\n",
    "            try:\n",
    "                location = geolocator.geocode(q)\n",
    "                if location:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Geocoding error for {station}: {e}\")\n",
    "            time.sleep(1) # Delay to prevent rate limiting\n",
    "\n",
    "        if location:\n",
    "            lat, lon = location.latitude, location.longitude\n",
    "            print(f\"[{i+1}/{len(stations)}] Found: {station}\")\n",
    "        else:\n",
    "            lat, lon = None, None\n",
    "            print(f\"[{i+1}/{len(stations)}] Could not locate: {station}\")\n",
    "\n",
    "    coords.append({\n",
    "        'Monitoring Station': station,\n",
    "        'Latitude': lat,\n",
    "        'Longitude': lon\n",
    "    })\n",
    "\n",
    "coords_df = pd.DataFrame(coords)\n",
    "df_mapready = df_all_tidy.merge(coords_df, on='Monitoring Station', how='left') \n",
    "\n",
    "df_mapready.to_csv(OUTPUT_FILE_MAPREADY, index=False)\n",
    "print(f\"\\n FINAL Map-ready dataset saved to: {OUTPUT_FILE_MAPREADY}\")\n",
    "\n",
    "missing_stations = coords_df[coords_df['Latitude'].isnull()]['Monitoring Station'].tolist()\n",
    "if missing_stations:\n",
    "    print(f\"\\n Still missing coordinates for {len(missing_stations)} station(s):\")\n",
    "    for m in missing_stations:\n",
    "        print(f\"- {m}\")\n",
    "else:\n",
    "    print(\"\\n All stations successfully geocoded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alejo_jharlyn",
   "language": "python",
   "name": "alejo_jharlyn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
